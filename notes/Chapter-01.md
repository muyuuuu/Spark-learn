# 大数据概述

1. 分布式计算带来算力
2. 存储空间、网络带宽的升级
3. 信息产生的变更，如自媒体

---

- 数据超大规模
- 具有规范的行列结构的数据称为结构化数据，其余为非结构化数据
- 处理大数据要足够快
- 大数据的价值密度低，单点价值高，如摄像头数据

---

1. 全部而非抽样，算力带来的提升
2. 效率而非精确，系统要求实时性
3. 相关而非因果，相关性而不是追求为什么

---

数据隐私与安全贯穿了：数据采集、数据存储和管理、数据处理和分析等大数据核心技术。重点是：**数据存储管理、数据处理与分析**，归为两个核心：分布式存储和分布式处理，也就是集群。

- 分布式存储：`GFS`分布式文件系统，`HDFS`开源实现的分布式文件系统，分布式数据库`BigTable, HBase, NoSql, NewSQL`等等等等。
- 分布式处理：`mapreduce, spark, flink`等，集群加速计算。

## 大数据计算模式

不同的场景需求下需要不同的计算模式。

- 批处理，一次性处理大量数据，如 mapreduce，spark
- 流计算，需要实时处理，给出实时响应，否则结果失去价值，如 Flink
- 图计算，地理信息、交通网络、社交网络等，如 pregel，graphx
- 查询分析计算，类似的 SQL 查询计算，如 Dremel，Hive 等

## 云计算

- 虚拟化，分布式存储和计算，多租户
- 通过网络，以服务的形式为用户提供非常廉价的 IT 资源，无需自建。
- IaaS，基础设施即服务，将基础设施（计算资源和存储）作为服务出租；PaaS，平台即服务，有一系列开发环境，可以部署开发软件；SaaS，软件即服务，卖软件，如带有版权的软件。


## mapreduce

分布式计算，像写单击程序一样写分布式程序，屏蔽了底层细节。

![](figure/mapreduce.png)

## Spark

不是单一产品，是完备的生态系统。底层的核心组件是 Spark Core，满足批处理的需求。在之上，开发满足其他需求的组件。

![](figure/Spark-structure.png)

与 hadoop 的对比

- hadoop 的 mapreduce 表达能力差
- 使用 mapreduce 反复迭代，每次迭代都需要读入和写出到磁盘，IO开销大
- 延迟高，任务衔接慢，只有一个 map 没做完，全部的 reduce 就不能开始

spark 计算模式本质是 mapreduce，也提供了其他操作。可以将计算结果放入内存，迭代计算效率较高。Spark 是单纯的计算框架，不具备存储能力。所以不会取代 hadoop，而是取代其中的计算框架 mapreduce，继续使用 hadoop 中的 HDFS。

## Flink

也是计算框架，擅长处理流数据。